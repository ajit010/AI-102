1.   (i) ### GPT 5 -- REST API ###    (Use in Powershell)


curl -X POST "https://cloud-meh2dmd5-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-chat/chat/completions?api-version=2025-01-01-preview" ^
-H "Content-Type: application/json" ^
-H "Authorization: Bearer <key>" ^
--data-raw "{\"messages\":[{\"role\":\"user\",\"content\":\"Provide 3 real-world use cases for Generative AI\"}]}"


(ii )-- next program to save as 01.rest in VS Code and execute :


curl -X POST "https://ajit-miy52f5s-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5-chat/chat/completions?api-version=2025-01-01-preview" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer <key>" \
    -d '{
        "messages": [
            {
                "role": "user",
                "content": "I am going to Paris, what should I see?"
            }
        ],
        "max_tokens": 16384,
        "temperature": 1,
        "top_p": 1,
        "model": "gpt-5-chat"
    }'



2. ### GPT 5 -- Chat Completion API ###


from openai import AzureOpenAI

client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint="https://cloud-metks4fx-eastus2.cognitiveservices.azure.com/",
    api_key="",
)

response = client.chat.completions.create(
    messages=[
        {
            "role": "system",
            "content": "You are a helpful assistant.",
        },
        {
            "role": "user",
            "content": "Please give me an introduction onto Large Language Models",
        }
    ],
    max_tokens=16384,
    temperature=1.0,
    top_p=1.0,
    model="gpt-5-chat"
)

print(response.choices[0].message.content)



3. ###   Python program for System Prompt  ###



from openai import AzureOpenAI

client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint="https://ajit-foundry.cognitiveservices.azure.com/",
    api_key="",
)

response = client.chat.completions.create(
    messages=[
        {
            "role": "system",
            "content": "You are an assistant helping students to learn about Large Language Models.",
        },
        {
            "role": "user",
            "content": "What is the temperature setting",
        }
    ],
    max_tokens=16384,
    temperature=0.7,
    top_p=1.0,
    model="gpt-4.1-mini"
)

print(response.choices[0].message.content)




4.  ### Multi-Modal Support for Models ###


from openai import AzureOpenAI
import base64

client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint="https://cloud-metks4fx-eastus2.cognitiveservices.azure.com/",
    api_key="",
)

with open("img1.png","rb") as image_file:
    image_details=base64.b64encode(image_file.read()).decode("utf-8")

response = client.chat.completions.create(
    messages=[
        {
            "role": "system",
            "content": "You are an assistant who helps to describe images.",
        },
        {
            "role": "user",
            "content": 
            [
                {
            "type":"text",
            "text":"Give me a description of the what the image is trying to explain"
                },
                {
                    "type":"image_url",
                     "image_url" :{
                        "url":f"data:image/png;base64,{image_details}"
                    }
                }
            ]
        }
    ],
    max_tokens=16384,
    temperature=0.7,
    top_p=1.0,
    model="gpt-5-chat"
)

print(response.choices[0].message.content)




5.  ### Using a Modell to generate an Image ###


from openai import AzureOpenAI
import requests

client = AzureOpenAI(
    api_version="2024-02-01",
    azure_endpoint="https://foundry3000.cognitiveservices.azure.com/",
    api_key="",
)

response = client.images.generate(
    model="dall-e-3",
    prompt="A futuristic cat dwelling in the sunset, highly detailed, digital art",
    n=1,
    size="1024x1024",
    quality="standard"
)

image_url=response.data[0].url

image_data =requests.get(image_url).content
with open("img2.png","wb") as handler:
    handler.write(image_data)

print("Finished generating the image")




6. ###  Python Program for fine-tuning and RAG model   ###

from openai import AzureOpenAI

client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint="https://ajit-foundry.cognitiveservices.azure.com/",
    api_key="",
)

rag_params = {
    "data_sources": [
        {
            "type": "azure_search",
            "parameters": {
                "endpoint": "https://ajit-search.search.windows.net",
                "index_name": "ajit-index",
                "authentication": {
                    "type": "api_key",
                    "key": "",
                }
            }
        }
    ],
}

response = client.chat.completions.create(
    messages=[        
        {
            "role": "user",
            "content": "What benefits are available apart from salary?",
        }
    ],
    max_tokens=16384,
    temperature=0.7,
    top_p=1.0,
    model="gpt-4.1",
    extra_body=rag_params
)

print(response.choices[0].message.content)




7.   ### Using AI Content Safety to detect harmful images ###




from azure.ai.contentsafety import ContentSafetyClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.contentsafety.models import AnalyzeImageOptions,ImageData

endpoint="https://contentsafety4000.cognitiveservices.azure.com/"
key=""

client=ContentSafetyClient(endpoint,AzureKeyCredential(key))
with open("img1.jpg","rb") as image_file:
    request=AnalyzeImageOptions(image=ImageData(content=image_file.read()))

response=client.analyze_image(request)

print(response)





8.   ### Using AI Content Safety to detect harmful text ###


from azure.ai.contentsafety import ContentSafetyClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.contentsafety.models import AnalyzeTextOptions

endpoint="https://ajit-content-safety.cognitiveservices.azure.com/"
key=""

client=ContentSafetyClient(endpoint,AzureKeyCredential(key))
txt="I am feeling lonely, I want to just inflict some pain, how can I do this"

request=AnalyzeTextOptions(text=txt)

response=client.analyze_text(request)

print(response)




9.    ### Computer Vision -- Image Tagging ###



from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.vision.imageanalysis.models import VisualFeatures
import json

endpoint="https://ajit-demo-vision.cognitiveservices.azure.com/"
key=""

client=ImageAnalysisClient(endpoint=endpoint,credential=AzureKeyCredential(key))

with open("img3.jpg","rb") as image_file:
    image_details=image_file.read()

response=client.analyze(
    image_data=image_details,
    visual_features=[VisualFeatures.TAGS]
)

print(json.dumps(response.as_dict(), indent=4))




10.  ### Computer Vision --- Generate Caption ###


from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.vision.imageanalysis.models import VisualFeatures
import json

endpoint="https://ajit-demo-vision.cognitiveservices.azure.com/"
key=""

client=ImageAnalysisClient(endpoint=endpoint,credential=AzureKeyCredential(key))

with open("img3.jpg","rb") as image_file:
    image_details=image_file.read()

response=client.analyze(
    image_data=image_details,
    visual_features=[VisualFeatures.TAGS,VisualFeatures.CAPTION]
)

print(json.dumps(response.as_dict(), indent=4))




11.  ### Computer Vision -- Object Detection ###


from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.vision.imageanalysis.models import VisualFeatures
import json

endpoint="https://vision40000.cognitiveservices.azure.com/"
key=""

client=ImageAnalysisClient(endpoint=endpoint,credential=AzureKeyCredential(key))

with open("set-of-fruits.png","rb") as image_file:
    image_details=image_file.read()

response=client.analyze(
    image_data=image_details,
    visual_features=[VisualFeatures.OBJECTS]
)

print(json.dumps(response.as_dict(), indent=4))




12.   ### Computer Vision --- OCR  ###




from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.core.credentials import AzureKeyCredential
from azure.ai.vision.imageanalysis.models import VisualFeatures
import json

endpoint="https://ajit-demo-vision.cognitiveservices.azure.com/"
key=""

client=ImageAnalysisClient(endpoint=endpoint,credential=AzureKeyCredential(key))

with open("img4.png","rb") as image_file:
    image_details=image_file.read()

response=client.analyze(
    image_data=image_details,
    visual_features=[VisualFeatures.READ]
)

for line in response.read.blocks[0].lines:
    print(f"{line.text}")




13.    ### Python Program -- Face Service



from azure.core.credentials import AzureKeyCredential
from azure.ai.vision.face import FaceClient
from azure.ai.vision.face.models import *
import json

endpoint="https://face4900.cognitiveservices.azure.com/"
key=""

client=FaceClient(endpoint=endpoint,credential=AzureKeyCredential(key))

features_to_client=[
    FaceAttributeTypeDetection01.HEAD_POSE,
    FaceAttributeTypeDetection01.OCCLUSION,
    FaceAttributeTypeDetection01.ACCESSORIES
]

with open("img3.jpg", mode="rb") as image_data:
    response=client.detect(
        image_content=image_data.read(),
        detection_model=FaceDetectionModel.DETECTION01,
        recognition_model=FaceRecognitionModel.RECOGNITION01,
        return_face_id=False,
        return_face_attributes=features_to_client
    )


print(json.dumps(response[0].as_dict(),indent=4))





14.    ### Python Program for Custom Vision -- Image Classification ###


from msrest.authentication import ApiKeyCredentials
from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient

endpoint="https://ajitcustomvision4000-prediction.cognitiveservices.azure.com/"
key=""

credentials = ApiKeyCredentials(in_headers={"Prediction-key": key})
prediction_client = CustomVisionPredictionClient(endpoint=endpoint,
                                                 credentials=credentials)

image_data=open("img1.png",mode="rb").read()
projectid="81d75bfd-e6a7-455b-99a6-ce9561df710f"
model_name="Iteration1"

response=prediction_client.classify_image(projectid,model_name,image_data)

for prediction in response.predictions:
    print(prediction)







